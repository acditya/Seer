# Seer ğŸ”®

**See through sound** - A voice-first navigation assistant for visually impaired users.

## Features

- ğŸ¤ **Voice-first interface** - Press-to-talk interaction
- ğŸ‘ï¸ **GPT-4o-mini vision** - AI sees through your camera in real-time
- ğŸ¤– **Continuous guidance** - AI speaks every 5 seconds automatically, like a friend
- ğŸ—£ï¸ **Natural speech** - iOS built-in TTS (reliable after recording)
- ğŸ“ **Checkpoint navigation** - "Take me to the door", "Find the elevator"
- ğŸ“³ **Haptic feedback** - Feel when recording/navigating
- â™¿ **Accessibility-focused** - Large touch targets, voice feedback

## Tech Stack

**Client:** Expo 54 (React Native + TypeScript)  
**Server:** Flask (Python)  
**AI:** OpenAI (Whisper STT + GPT-4o-mini Vision) + iOS TTS

## Quick Start

### 1. Server Setup

```bash
cd server
python -m venv .venv
.venv\Scripts\activate          # Windows
# source .venv/bin/activate     # Mac/Linux

pip install -r requirements.txt
python main.py
```

### 2. Configure Environment

Create `server/.env`:

```bash
PORT=8000

# OpenAI API (for everything: Whisper STT + GPT-4o-mini vision)
OPENAI_API_KEY=sk-proj-your_key_here
```

### 3. Client Setup

```bash
cd client
npm install

# Update app.config.ts with your local IP
# serverUrl: 'http://YOUR_IP:8000'

npm start
```

### 4. Run on iPhone

1. Install Expo Go from App Store
2. Scan QR code from terminal
3. Grant camera & microphone permissions
4. Start navigating!

## Usage

**Natural & Continuous:**

1. **Press and hold** the green button
2. **Say your destination**: "the door", "elevator", "bathroom"
3. **Release** â†’ AI confirms: "There it is! The door, straight ahead."
4. **Walk naturally** â†’ AI guides you every 5 seconds automatically
5. **AI speaks**: "You're good, keep going", "Stop. Chair on your right."
6. **Arrival**: "Perfect! You're right at the door!"

**Continuous guidance:** AI sees through your camera every 5 seconds and speaks naturally like a friend walking with you.

### Voice Commands

- **"repeat"** - Hear last instruction again
- **"stop"** - End navigation
- **"new checkpoint [name]"** - Change destination
- **"I'm here"** - Mark destination reached

## Project Structure

```
seer/
â”œâ”€â”€ client/          # Expo React Native app
â”‚   â”œâ”€â”€ App.tsx
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api.ts                    # Server communication
â”‚   â”‚   â”œâ”€â”€ hooks/useNavigationLoop.ts # Navigation state machine
â”‚   â”‚   â””â”€â”€ components/               # UI components
â”‚   â””â”€â”€ app.config.ts                 # App configuration
â”‚
â””â”€â”€ server/          # Flask Python API
    â”œâ”€â”€ main.py                       # API endpoints
    â”œâ”€â”€ stt.py                        # OpenAI Whisper STT
    â”œâ”€â”€ tts.py                        # Text passthrough (iOS TTS on client)
    â”œâ”€â”€ plan.py                       # GPT-4o-mini vision navigation
    â””â”€â”€ state.py                      # Scene state tracking
```

## API Endpoints

- `POST /stt` - Speech to text (OpenAI Whisper)
- `POST /tts` - Text passthrough (client uses iOS TTS)
- `POST /plan` - Vision-based navigation (GPT-4o-mini analyzes camera image)
- `GET /scene` - Current scene state

## Development

**Server:**
```bash
cd server && python main.py
```

**Client:**
```bash
cd client && npm start
```

## Troubleshooting

**"Network error"**
- Update `serverUrl` in `client/app.config.ts` with your local IP
- Ensure server is running: visit `http://localhost:8000`
- Check both devices on same WiFi

**No camera preview**
- Grant camera permissions in iOS Settings â†’ Expo Go

**Audio doesn't play**
- Check iPhone is not on silent mode
- Grant microphone permissions

## License

MIT

---

Built for accessibility. Powered by AI. ğŸ¯
